# -*- coding: utf-8 -*-
"""EmotionalStateCapstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14fTeKHSw5lN5Vd_eFceJtLFVzQdbdGYu

### **Setting Up the Requirements**
"""

!pip install transformers torch torchvision torchaudio
!pip install scikit-learn pandas numpy matplotlib seaborn
!pip install wordcloud textblob

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
import re
import string
from textblob import TextBlob
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

# Setting up plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("Emotional State Detection Model")
print("=" * 50)

# Setting Up the Datasets
print("Loading datasets...")

train_df = pd.read_csv('training.csv')
test_df = pd.read_csv('test.csv')
val_df = pd.read_csv('validation.csv')

print(f"Training set shape: {train_df.shape}")
print(f"Test set shape: {test_df.shape}")
print(f"Validation set shape: {val_df.shape}")

#Exploratory Data Analysis
print("Data Exploration...")

# Display basic info about the datasets
print("\nTraining Data Info:")
print(train_df.info())
print("\nFirst few rows of training data:")
print(train_df.head())

# Check for missing values
print(f"\nMissing values in training set: {train_df.isnull().sum().sum()}")
print(f"Missing values in test set: {test_df.isnull().sum().sum()}")
print(f"Missing values in validation set: {val_df.isnull().sum().sum()}")

# Analyze label distribution
print("\nLabel Distribution Analysis:")
print(train_df['label'].value_counts().sort_index())

# Create emotion mapping
emotion_mapping = {
    0: 'Sadness/Depression',
    1: 'Joy/Happiness',
    2: 'Love/Affection',
    3: 'Anger/Frustration',
    4: 'Fear/Anxiety',
    5: 'Surprise/Unexpected'
}

train_df['emotion'] = train_df['label'].map(emotion_mapping)
val_df['emotion'] = val_df['label'].map(emotion_mapping)
test_df['emotion'] = test_df['label'].map(emotion_mapping)

# Visualizing label distribution
plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
train_df['label'].value_counts().sort_index().plot(kind='bar')
plt.title('Training Set - Label Distribution')
plt.xlabel('Emotion Label')
plt.ylabel('Count')

plt.subplot(2, 2, 2)
val_df['label'].value_counts().sort_index().plot(kind='bar')
plt.title('Validation Set - Label Distribution')
plt.xlabel('Emotion Label')
plt.ylabel('Count')

plt.subplot(2, 2, 3)
train_df['emotion'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Training Set - Emotion Distribution')
plt.ylabel('')

plt.subplot(2, 2, 4)
train_df['text_length'] = train_df['text'].str.len()
plt.hist(train_df['text_length'], bins=30, alpha=0.7)
plt.title('Text Length Distribution')
plt.xlabel('Character Count')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Text Preprocessing
print("Text Preprocessing...")

def preprocess_text(text):
    """
    Comprehensive text preprocessing function
    """
    if pd.isna(text):
        return ""
    text = text.lower()                                               #Converting to Lowercase

    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)         #Removing any URLS
    text = re.sub(r'@\w+|#\w+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# Applying preprocessing
print("Preprocessing training data...")
train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)
print("Preprocessing validation data...")
val_df['cleaned_text'] = val_df['text'].apply(preprocess_text)
print("Preprocessing test data...")
test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)

# Removing empty texts
train_df = train_df[train_df['cleaned_text'].str.len() > 0]
val_df = val_df[val_df['cleaned_text'].str.len() > 0]
test_df = test_df[test_df['cleaned_text'].str.len() > 0]

print(f"After preprocessing - Training: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}")

#Feature Engineering
print("Feature Engineering:")

# Create TF-IDF features
tfidf_vectorizer = TfidfVectorizer(
    max_features=10000,
    ngram_range=(1, 2),
    stop_words='english',
    max_df=0.95,
    min_df=2
)

# Fitting on training data and transform all datasets
X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])
X_val_tfidf = tfidf_vectorizer.transform(val_df['cleaned_text'])
X_test_tfidf = tfidf_vectorizer.transform(test_df['cleaned_text'])

# Extracting labels
y_train = train_df['label'].values
y_val = val_df['label'].values
y_test = test_df['label'].values

print(f"TF-IDF feature matrix shape: {X_train_tfidf.shape}")
print(f"Number of unique words: {len(tfidf_vectorizer.vocabulary_)}")

#Model Training and Evaluation
print("Training Multiple Models:")

# Initializing the models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='rbf', random_state=42, probability=True)
}

# Training and evaluating the models
results = {}
trained_models = {}

for name, model in models.items():
    print(f"\nTraining {name}...")

    # Training the model
    model.fit(X_train_tfidf, y_train)
    trained_models[name] = model

    # Making predictions
    y_train_pred = model.predict(X_train_tfidf)
    y_val_pred = model.predict(X_val_tfidf)

    train_accuracy = accuracy_score(y_train, y_train_pred)
    val_accuracy = accuracy_score(y_val, y_val_pred)

    results[name] = {
        'train_accuracy': train_accuracy,
        'val_accuracy': val_accuracy,
        'model': model
    }

    print(f"{name} - Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}")

# Model Comparison

print("Model Comparison:")
comparison_df = pd.DataFrame(results).T
comparison_df = comparison_df.drop('model', axis=1)
print(comparison_df)

# Determining best model
best_model_name = comparison_df['val_accuracy'].idxmax()
best_model = trained_models[best_model_name]
print(f"\nBest Model: {best_model_name}")

print(f"Detailed Evaluation :- {best_model_name}")

y_val_pred = best_model.predict(X_val_tfidf)

# Classification report
print("\nClassification Report:")
print(classification_report(y_val, y_val_pred, target_names=[emotion_mapping[i] for i in range(6)]))

# Confusion Matrix
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_val, y_val_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=[emotion_mapping[i] for i in range(6)],
            yticklabels=[emotion_mapping[i] for i in range(6)])
plt.title(f'Confusion Matrix - {best_model_name}')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.tight_layout()
plt.show()

# Test Set Evaluation
print("Final Test Set Evaluation:")

# Predictions on test set
y_test_pred = best_model.predict(X_test_tfidf)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Test Accuracy: {test_accuracy:.4f}")
print("\nTest Set Classification Report:")
print(classification_report(y_test, y_test_pred, target_names=[emotion_mapping[i] for i in range(6)]))

# Feature Importance Analysis
if best_model_name in ['Logistic Regression', 'Random Forest']:
    print(f"Feature Importance Analysis :- {best_model_name}")

    if best_model_name == 'Logistic Regression':
        # Get feature names and coefficients
        feature_names = tfidf_vectorizer.get_feature_names_out()

        # For multiclass, we are getting coefficients for each class
        coefficients = best_model.coef_

        # Showing top features for each emotion class
        for class_idx in range(len(emotion_mapping)):
            print(f"\nTop 10 words for {emotion_mapping[class_idx]}:")
            top_indices = coefficients[class_idx].argsort()[-10:][::-1]
            for idx in top_indices:
                print(f"  {feature_names[idx]}: {coefficients[class_idx][idx]:.4f}")

    elif best_model_name == 'Random Forest':
        feature_names = tfidf_vectorizer.get_feature_names_out()
        importances = best_model.feature_importances_

        top_indices = importances.argsort()[-10:][::-1]

        print("\nTop 10 Most Important Features:")
        for idx in top_indices:
            print(f"  {feature_names[idx]}: {importances[idx]:.4f}")

# Prediction Function

print("Creating Prediction Function:")

def predict_emotion(text):
    # Preprocess the text
    cleaned_text = preprocess_text(text)

    # Transform to TF-IDF
    text_tfidf = tfidf_vectorizer.transform([cleaned_text])

    # Making prediction
    prediction = best_model.predict(text_tfidf)[0]
    probability = best_model.predict_proba(text_tfidf)[0]

    # Getting emotion name
    emotion = emotion_mapping[prediction]
    confidence = probability[prediction]

    return {
        'text': text,
        'predicted_label': prediction,
        'predicted_emotion': emotion,
        'confidence': confidence,
        'all_probabilities': {emotion_mapping[i]: prob for i, prob in enumerate(probability)}
    }

# Testing the prediction function
sample_texts = [
    "I feel so happy and excited about this news!",
    "This makes me really angry and frustrated",
    "I'm feeling quite sad and lonely today",
    "I love spending time with my family",
    "I'm scared about what might happen next",
    "What a surprising turn of events!"
]

print("Testing Prediction Function:")
for text in sample_texts:
    result = predict_emotion(text)
    print(f"Text: '{text}'")
    print(f"Predicted: {result['predicted_emotion']} (Confidence: {result['confidence']:.3f})")
    print()

# Save Model and Results

print("Saving Results...")

import pickle

# Saving the best model
with open(f'best_emotion_model_{best_model_name.lower().replace(" ", "_")}.pkl', 'wb') as f:
    pickle.dump(best_model, f)

# Saving the TF-IDF vectorizer
with open('tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(tfidf_vectorizer, f)

# Saving the emotion mapping
with open('emotion_mapping.pkl', 'wb') as f:
    pickle.dump(emotion_mapping, f)

# Creating a summary report
summary_report = f"""
Emotional State Detection Model - Summary Report
===============================================

Dataset Information:
- Training samples: {len(train_df)}
- Validation samples: {len(val_df)}
- Test samples: {len(test_df)}
- Number of emotion classes: {len(emotion_mapping)}

Best Model: {best_model_name}
- Validation Accuracy: {results[best_model_name]['val_accuracy']:.4f}
- Test Accuracy: {test_accuracy:.4f}

Model Performance Summary:
{comparison_df.to_string()}

Emotion Classes:
{emotion_mapping}

Feature Engineering:
- TF-IDF Vectorization
- Max features: 10,000
- N-gram range: (1, 2)
- Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}

Files Generated:
- best_emotion_model_{best_model_name.lower().replace(" ", "_")}.pkl
- tfidf_vectorizer.pkl
- emotion_mapping.pkl
"""

with open('model_summary.txt', 'w') as f:
    f.write(summary_report)

print("Model training completed successfully")
print("\nFiles saved:")
print("- Model file")
print("- TF-IDF vectorizer")
print("- Emotion mapping")
print("- Summary report")

# Downloading files
print("Downloading files..")
files.download(f'best_emotion_model_{best_model_name.lower().replace(" ", "_")}.pkl')
files.download('tfidf_vectorizer.pkl')
files.download('emotion_mapping.pkl')
files.download('model_summary.txt')

print("All done! Your emotional state detection model is ready to use!")

plt.tight_layout()
plt.show()